{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c8fdeb",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis Report Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b00584",
   "metadata": {},
   "source": [
    "## Loading the Sentiment140 dataset containing 1.6M Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a29dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", header= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e8d082",
   "metadata": {},
   "source": [
    "#### Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34935acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   0       1600000 non-null  int64 \n",
      " 1   1       1600000 non-null  int64 \n",
      " 2   2       1600000 non-null  object\n",
      " 3   3       1600000 non-null  object\n",
      " 4   4       1600000 non-null  object\n",
      " 5   5       1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88035036",
   "metadata": {},
   "source": [
    "#### Hence, no missing value is present in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4143c373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of total tweets in the dataset\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1375da66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of positive tweets in the dataset\n",
    "len(df[df[0]==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897c9a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of negative tweets in the dataset\n",
    "len(df[df[0]==4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91606e0",
   "metadata": {},
   "source": [
    "This dataset is balanced into two categories- positive and negative. \n",
    "No neutral labelling is present in this dataset. So, We need to prepare the dataset according to our objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313051e0",
   "metadata": {},
   "source": [
    "#### Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3be0b04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user_name</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target     user_id                          date     query  \\\n",
       "0             0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1             0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2             0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3             0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4             0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...         ...         ...                           ...       ...   \n",
       "1599995       4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996       4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997       4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998       4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999       4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "               user_name                                              tweet  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=['target','user_id','date','query','user_name','tweet']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3c72d4",
   "metadata": {},
   "source": [
    "#### Dropping All other columns except the tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e797de82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet\n",
       "0        @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1        is upset that he can't update his Facebook by ...\n",
       "2        @Kenichan I dived many times for the ball. Man...\n",
       "3          my whole body feels itchy and like its on fire \n",
       "4        @nationwideclass no, it's not behaving at all....\n",
       "...                                                    ...\n",
       "1599995  Just woke up. Having no school is the best fee...\n",
       "1599996  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1600000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop(['target','user_id','date','query','user_name'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2aa002",
   "metadata": {},
   "source": [
    "#### Cleaning the Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "babe7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "121430de",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def replace_emojis(t):\n",
    "    emoji_happy = [\"\\U0001F600\",\"\\U0001F601\", \"\\U0001F602\",\"\\U0001F603\",\"\\U0001F604\",\"\\U0001F605\",\n",
    "                       \"\\U0001F606\",\"\\U0001F607\",\"\\U0001F609\",\"\\U0001F60A\", \"\\U0001F642\",\"\\U0001F643\",\"\\U0001F923\",r\"\\U0001F970\",\"\\U0001F60D\", r\"\\U0001F929\",\"\\U0001F618\",\"\\U0001F617\",\n",
    "                       r\"\\U000263A\", \"\\U0001F61A\", \"\\U0001F619\", r\"\\U0001F972\", \"\\U0001F60B\", \"\\U0001F61B\", \"\\U0001F61C\", r\"\\U0001F92A\",\n",
    "                       \"\\U0001F61D\", \"\\U0001F911\", \"\\U0001F917\", r\"\\U0001F92D\", r\"\\U0001F92B\",\"\\U0001F914\",\"\\U0001F910\", r\"\\U0001F928\", \"\\U0001F610\", \"\\U0001F611\",\n",
    "                       \"\\U0001F636\", \"\\U0001F60F\",\"\\U0001F612\", \"\\U0001F644\",\"\\U0001F62C\",\"\\U0001F925\",\"\\U0001F60C\",\"\\U0001F614\",\"\\U0001F62A\",\n",
    "                       \"\\U0001F924\",\"\\U0001F634\", \"\\U0001F920\", r\"\\U0001F973\", r\"\\U0001F978\",\"\\U0001F60E\",\"\\U0001F913\", r\"\\U0001F9D0\"]\n",
    "    emoji_sad = [\"\\U0001F637\",\"\\U0001F912\",\"\\U0001F915\",\"\\U0001F922\", r\"\\U0001F92E\",\"\\U0001F927\", r\"\\U0001F975\", r\"\\U0001F976\", r\"\\U0001F974\",\n",
    "                       \"\\U0001F635\", r\"\\U0001F92F\", \"\\U0001F615\",\"\\U0001F61F\",\"\\U0001F641\", r\"\\U0002639\",\"\\U0001F62E\",\"\\U0001F62F\",\"\\U0001F632\",\n",
    "                       \"\\U0001F633\", r\"\\U0001F97A\",\"\\U0001F626\",\"\\U0001F627\",\"\\U0001F628\",\"\\U0001F630\",\"\\U0001F625\",\"\\U0001F622\",\"\\U0001F62D\",\n",
    "                       \"\\U0001F631\",\"\\U0001F616\",\"\\U0001F623\"\t,\"\\U0001F61E\",\"\\U0001F613\",\"\\U0001F629\",\"\\U0001F62B\", r\"\\U0001F971\",\n",
    "                       \"\\U0001F624\",\"\\U0001F621\",\"\\U0001F620\", r\"\\U0001F92C\",\"\\U0001F608\",\"\\U0001F47F\",\"\\U0001F480\", r\"\\U0002620\"]\n",
    "\n",
    "    words = t.split()\n",
    "    reformed = []\n",
    "    for w in words:\n",
    "        if w in emoji_happy:\n",
    "            reformed.append(\"happy\")\n",
    "        elif w in emoji_sad:\n",
    "            reformed.append(\"sad\") \n",
    "        else:\n",
    "            reformed.append(w)\n",
    "    t = \" \".join(reformed)\n",
    "    return t\n",
    "\n",
    "\n",
    "def replace_smileys(t):\n",
    "    emoticons_happy = set([':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}', ':D',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)', '<3'])\n",
    "\n",
    "    emoticons_sad = set([':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('])  \n",
    "\n",
    "    words = t.split()\n",
    "    reformed = []\n",
    "    for w in words:\n",
    "        if w in emoticons_happy:\n",
    "            reformed.append(\"happy\")\n",
    "        elif w in emoticons_sad:\n",
    "            reformed.append(\"sad\") \n",
    "        else:\n",
    "            reformed.append(w)\n",
    "    t = \" \".join(reformed)\n",
    "    return t\n",
    "\n",
    "def replace_contractions(t):\n",
    "    cont = {\"aren't\" : 'are not', \"can't\" : 'cannot', \"couln't\": 'could not', \"didn't\": 'did not', \"doesn't\" : 'does not',\n",
    "  \"hadn't\": 'had not', \"haven't\": 'have not', \"he's\" : 'he is', \"she's\" : 'she is', \"he'll\" : \"he will\", \n",
    "  \"she'll\" : 'she will',\"he'd\": \"he would\", \"she'd\":\"she would\", \"here's\" : \"here is\", \n",
    "   \"i'm\" : 'i am', \"i've\"\t: \"i have\", \"i'll\" : \"i will\", \"i'd\" : \"i would\", \"isn't\": \"is not\", \n",
    "   \"it's\" : \"it is\", \"it'll\": \"it will\", \"mustn't\" : \"must not\", \"shouldn't\" : \"should not\", \"that's\" : \"that is\", \n",
    "   \"there's\" : \"there is\", \"they're\" : \"they are\", \"they've\" : \"they have\", \"they'll\" : \"they will\",\n",
    "   \"they'd\" : \"they would\", \"wasn't\" : \"was not\", \"we're\": \"we are\", \"we've\":\"we have\", \"we'll\": \"we will\", \n",
    "   \"we'd\" : \"we would\", \"weren't\" : \"were not\", \"what's\" : \"what is\", \"where's\" : \"where is\", \"who's\": \"who is\",\n",
    "   \"who'll\" :\"who will\", \"won't\":\"will not\", \"wouldn't\" : \"would not\", \"you're\": \"you are\", \"you've\":\"you have\",\n",
    "   \"you'll\" : \"you will\", \"you'd\" : \"you would\", \"mayn't\" : \"may not\"}\n",
    "    words = t.split()\n",
    "    reformed = []\n",
    "    for w in words:\n",
    "        if w in cont:\n",
    "            reformed.append(cont[w])\n",
    "        else:\n",
    "            reformed.append(w)\n",
    "    t = \" \".join(reformed)\n",
    "    return t  \n",
    "\n",
    "def remove_single_letter_words(t):\n",
    "    words = t.split()\n",
    "    reformed = []\n",
    "    for w in words:\n",
    "        if len(w) > 1:\n",
    "            reformed.append(w)\n",
    "    t = \" \".join(reformed)\n",
    "    return t  \n",
    "\n",
    "def cleantweet(t):\n",
    "    # replace handwritten emojis with their feeling associated\n",
    "    t = replace_smileys(t)\n",
    "    \n",
    "    # convert to lowercase\n",
    "    t = t.lower() \n",
    "    \n",
    "    # replace short forms used in english  with their actual words\n",
    "    t = replace_contractions(t) \n",
    "    \n",
    "    # replace unicode emojis with their feeling a@ashchanchlanissociated\n",
    "    t = replace_emojis(t) \n",
    "    \n",
    "    # remove emojis other than smiley emojis\n",
    "    t = emoji_pattern.sub(r'', t) \n",
    "    \n",
    "    # remove NON- ASCII characters\n",
    "    t = re.sub('\\\\\\\\u[0-9A-Fa-f]{4}','', t) \n",
    "    \n",
    "    # remove numbers # re.sub(\"\\d+\", \"\", t)\n",
    "    t = re.sub(\"[0-9]\", \"\", t)\n",
    "    \n",
    "    # remove '#'\n",
    "    t = re.sub('#', '', t) \n",
    "    \n",
    "    # remove '@'\n",
    "    t = re.sub('@[A-Za-z0–9]+', '', t) \n",
    "    \n",
    "    # remove usernames\n",
    "    t = re.sub('@[^\\s]+', '', t) \n",
    "    \n",
    "    # remove retweet 'RT'\n",
    "    t = re.sub('RT[\\s]+', '', t)\n",
    "    \n",
    "    # remove links (URLs/ links)\n",
    "    t = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '', t) \n",
    "    \n",
    "    # remove punctuations\n",
    "    t = re.sub('[!\"$%&\\'()*+,-./:@;<=>?[\\\\]^_`{|}~]', '', t) \n",
    "    \n",
    "    t = t.replace('\\\\\\\\', '')\n",
    "    t = t.replace('\\\\', '')\n",
    "    \n",
    "    # removes single letter words\n",
    "    t = remove_single_letter_words(t)\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f3adf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww that is bummer you shoulda got david carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he cannot update his facebook by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>no it is not behaving at all am mad why am her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>just woke up having no school is the best feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>thewdbcom very cool to hear old walt interviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>happy th birthday to my boo of alll time tupac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>happy charitytuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  \\\n",
       "0        @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1        is upset that he can't update his Facebook by ...   \n",
       "2        @Kenichan I dived many times for the ball. Man...   \n",
       "3          my whole body feels itchy and like its on fire    \n",
       "4        @nationwideclass no, it's not behaving at all....   \n",
       "...                                                    ...   \n",
       "1599995  Just woke up. Having no school is the best fee...   \n",
       "1599996  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999  happy #charitytuesday @theNSPCC @SparksCharity...   \n",
       "\n",
       "                                                      text  \n",
       "0        awww that is bummer you shoulda got david carr...  \n",
       "1        is upset that he cannot update his facebook by...  \n",
       "2        dived many times for the ball managed to save ...  \n",
       "3           my whole body feels itchy and like its on fire  \n",
       "4        no it is not behaving at all am mad why am her...  \n",
       "...                                                    ...  \n",
       "1599995  just woke up having no school is the best feel...  \n",
       "1599996    thewdbcom very cool to hear old walt interviews  \n",
       "1599997  are you ready for your mojo makeover ask me fo...  \n",
       "1599998  happy th birthday to my boo of alll time tupac...  \n",
       "1599999                               happy charitytuesday  \n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['tweet'].apply(cleantweet)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1593e9",
   "metadata": {},
   "source": [
    "#### Preprocessing the text by tokenizing the tweet , then removing all known stopwords, then stemming and lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "792cbb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mainak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mainak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b067112d",
   "metadata": {},
   "source": [
    "#### Storing all English stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91ae8409",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bc31d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    \n",
    "    #remove stopwords by tokenizing\n",
    "    tweet_tokens = word_tokenize(tweet)\n",
    "    filtered_words = [ word for word in tweet_tokens if word not in stop_words]\n",
    "    \n",
    "    #Stemming \n",
    "    ps = PorterStemmer()\n",
    "    stemmed_words = [ ps.stem(w) for w in filtered_words]\n",
    "    \n",
    "    #Lemmatizing\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_words = [ lemmatizer.lemmatize(w, pos='a') for w in stemmed_words]\n",
    "    \n",
    "    return \" \".join(lemma_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82c75112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behav mad see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>woke school best feel ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>thewdbcom cool hear old walt interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>readi mojo makeov ask detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>happi th birthday boo alll time tupac amaru sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>happi charitytuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  \\\n",
       "0        @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1        is upset that he can't update his Facebook by ...   \n",
       "2        @Kenichan I dived many times for the ball. Man...   \n",
       "3          my whole body feels itchy and like its on fire    \n",
       "4        @nationwideclass no, it's not behaving at all....   \n",
       "...                                                    ...   \n",
       "1599995  Just woke up. Having no school is the best fee...   \n",
       "1599996  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999  happy #charitytuesday @theNSPCC @SparksCharity...   \n",
       "\n",
       "                                                      text  \n",
       "0             awww bummer shoulda got david carr third day  \n",
       "1        upset updat facebook text might cri result sch...  \n",
       "2             dive mani time ball manag save rest go bound  \n",
       "3                          whole bodi feel itchi like fire  \n",
       "4                                            behav mad see  \n",
       "...                                                    ...  \n",
       "1599995                         woke school best feel ever  \n",
       "1599996             thewdbcom cool hear old walt interview  \n",
       "1599997                       readi mojo makeov ask detail  \n",
       "1599998  happi th birthday boo alll time tupac amaru sh...  \n",
       "1599999                               happi charitytuesday  \n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(preprocess_tweet)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeff1461",
   "metadata": {},
   "source": [
    "#### Preparing the Dataset using TextBlob library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "680f82c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behav mad see</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>woke school best feel ever</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>thewdbcom cool hear old walt interview</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>readi mojo makeov ask detail</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>happi th birthday boo alll time tupac amaru sh...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>happi charitytuesday</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  \\\n",
       "0        @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1        is upset that he can't update his Facebook by ...   \n",
       "2        @Kenichan I dived many times for the ball. Man...   \n",
       "3          my whole body feels itchy and like its on fire    \n",
       "4        @nationwideclass no, it's not behaving at all....   \n",
       "...                                                    ...   \n",
       "1599995  Just woke up. Having no school is the best fee...   \n",
       "1599996  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999  happy #charitytuesday @theNSPCC @SparksCharity...   \n",
       "\n",
       "                                                      text  polarity  \\\n",
       "0             awww bummer shoulda got david carr third day     0.200   \n",
       "1        upset updat facebook text might cri result sch...     0.000   \n",
       "2             dive mani time ball manag save rest go bound     0.000   \n",
       "3                          whole bodi feel itchi like fire     0.200   \n",
       "4                                            behav mad see    -0.625   \n",
       "...                                                    ...       ...   \n",
       "1599995                         woke school best feel ever     1.000   \n",
       "1599996             thewdbcom cool hear old walt interview     0.225   \n",
       "1599997                       readi mojo makeov ask detail     0.000   \n",
       "1599998  happi th birthday boo alll time tupac amaru sh...     0.000   \n",
       "1599999                               happi charitytuesday     0.000   \n",
       "\n",
       "         subjectivity  \n",
       "0               0.450  \n",
       "1               0.000  \n",
       "2               0.000  \n",
       "3               0.400  \n",
       "4               1.000  \n",
       "...               ...  \n",
       "1599995         0.300  \n",
       "1599996         0.425  \n",
       "1599997         0.000  \n",
       "1599998         0.000  \n",
       "1599999         0.000  \n",
       "\n",
       "[1600000 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "df[['polarity', 'subjectivity']] = df['text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cdb5faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelling(pol):\n",
    "    if pol>=0.1:\n",
    "        return 4\n",
    "    elif pol<=-0.1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecd49d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.450</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dive mani time ball manag save rest go bound</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.400</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behav mad see</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>woke school best feel ever</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>thewdbcom cool hear old walt interview</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.425</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>readi mojo makeov ask detail</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>happi th birthday boo alll time tupac amaru sh...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>happi charitytuesday</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  \\\n",
       "0        @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1        is upset that he can't update his Facebook by ...   \n",
       "2        @Kenichan I dived many times for the ball. Man...   \n",
       "3          my whole body feels itchy and like its on fire    \n",
       "4        @nationwideclass no, it's not behaving at all....   \n",
       "...                                                    ...   \n",
       "1599995  Just woke up. Having no school is the best fee...   \n",
       "1599996  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999  happy #charitytuesday @theNSPCC @SparksCharity...   \n",
       "\n",
       "                                                      text  polarity  \\\n",
       "0             awww bummer shoulda got david carr third day     0.200   \n",
       "1        upset updat facebook text might cri result sch...     0.000   \n",
       "2             dive mani time ball manag save rest go bound     0.000   \n",
       "3                          whole bodi feel itchi like fire     0.200   \n",
       "4                                            behav mad see    -0.625   \n",
       "...                                                    ...       ...   \n",
       "1599995                         woke school best feel ever     1.000   \n",
       "1599996             thewdbcom cool hear old walt interview     0.225   \n",
       "1599997                       readi mojo makeov ask detail     0.000   \n",
       "1599998  happi th birthday boo alll time tupac amaru sh...     0.000   \n",
       "1599999                               happi charitytuesday     0.000   \n",
       "\n",
       "         subjectivity  sentiment  \n",
       "0               0.450          4  \n",
       "1               0.000          2  \n",
       "2               0.000          2  \n",
       "3               0.400          4  \n",
       "4               1.000          0  \n",
       "...               ...        ...  \n",
       "1599995         0.300          4  \n",
       "1599996         0.425          4  \n",
       "1599997         0.000          2  \n",
       "1599998         0.000          2  \n",
       "1599999         0.000          2  \n",
       "\n",
       "[1600000 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment']=df['polarity'].apply(labelling)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6377956c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539818"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Positive Tweets\n",
    "len(df[df['sentiment']==4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bee078e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "845226"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Neutral Tweets\n",
    "len(df[df['sentiment']==2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ce48e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214956"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Negative Tweets\n",
    "len(df[df['sentiment']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6d9f12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000,)\n"
     ]
    }
   ],
   "source": [
    "y = df['sentiment']\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac0ab23",
   "metadata": {},
   "source": [
    "#### Vectorization of text data using Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8196c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe0bf9c",
   "metadata": {},
   "source": [
    "#### Splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b90a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=41,shuffle=True,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c2153c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.array as da\n",
    "classes = da.unique(y).compute()\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80001b70",
   "metadata": {},
   "source": [
    "### Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea345a",
   "metadata": {},
   "source": [
    "#### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04683b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8284354166666666\n",
      "Score: 0.8272416666666667\n",
      "Score: 0.8283875\n",
      "Score: 0.82815\n",
      "Score: 0.8281729166666667\n",
      "Score: 0.8279416666666667\n",
      "Score: 0.8280916666666667\n",
      "Score: 0.8280958333333334\n",
      "Score: 0.82811875\n",
      "Score: 0.8281229166666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from dask_ml.wrappers import Incremental\n",
    "est = SGDClassifier(loss='log', penalty='l2', tol=0e-3)\n",
    "inc = Incremental(est, scoring='accuracy')\n",
    "for _ in range(10):\n",
    "    inc.partial_fit(X_train, y_train, classes=classes)\n",
    "    print('Score:', inc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41384e8d",
   "metadata": {},
   "source": [
    "#### Multinomial Naive-Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a8b8630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7365145833333333\n",
      "Score: 0.7486979166666666\n",
      "Score: 0.753425\n",
      "Score: 0.755725\n",
      "Score: 0.7569895833333333\n",
      "Score: 0.7579145833333333\n",
      "Score: 0.7585354166666667\n",
      "Score: 0.7590020833333333\n",
      "Score: 0.75928125\n",
      "Score: 0.7595041666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from dask_ml.wrappers import Incremental\n",
    "mnb = MultinomialNB()\n",
    "inc2 = Incremental(mnb, scoring='accuracy')\n",
    "for _ in range(10):\n",
    "    inc2.partial_fit(X_train, y_train, classes=classes)\n",
    "    print('Score:', inc2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be8218e",
   "metadata": {},
   "source": [
    "#### Bernoulli Naive-Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "540e40f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.82799375\n",
      "Score: 0.8483145833333333\n",
      "Score: 0.8530666666666666\n",
      "Score: 0.85436875\n",
      "Score: 0.8544395833333334\n",
      "Score: 0.8542041666666667\n",
      "Score: 0.8537125\n",
      "Score: 0.85314375\n",
      "Score: 0.85259375\n",
      "Score: 0.8522354166666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from dask_ml.wrappers import Incremental\n",
    "bnb = BernoulliNB()\n",
    "inc3 = Incremental(bnb, scoring='accuracy')\n",
    "for _ in range(10):\n",
    "    inc3.partial_fit(X_train, y_train, classes=classes)\n",
    "    print('Score:', inc3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5010e0",
   "metadata": {},
   "source": [
    "#### Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eade89a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.94745\n",
      "Score: 0.9484541666666667\n",
      "Score: 0.9499958333333334\n",
      "Score: 0.95155625\n",
      "Score: 0.9510979166666667\n",
      "Score: 0.9514583333333333\n",
      "Score: 0.9529291666666667\n",
      "Score: 0.95285625\n",
      "Score: 0.9527020833333333\n",
      "Score: 0.9520270833333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from dask_ml.wrappers import Incremental\n",
    "per = Perceptron()\n",
    "inc4 = Incremental(per, scoring='accuracy')\n",
    "for _ in range(10):\n",
    "    inc4.partial_fit(X_train, y_train, classes=classes)\n",
    "    print('Score:', inc4.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cdfcb1",
   "metadata": {},
   "source": [
    "### Incremental learning on Perceptron Model gives 95.20% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe5abc3",
   "metadata": {},
   "source": [
    "#### Training SVM Model on 1 Lakh Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7b76c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e848c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2 = TfidfVectorizer()\n",
    "X = vec2.fit_transform(df2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75686207",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df2['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9a8cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=41,shuffle=True,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b26a85a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', probability=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# classify using support vector classifier\n",
    "svm = svm.SVC(kernel = 'linear', probability=True)\n",
    "\n",
    "# fit the SVC model based on the given training data\n",
    "svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9d0fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4578068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291808e",
   "metadata": {},
   "source": [
    "### Support Vector classifier gives 95.54% Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae90d8be",
   "metadata": {},
   "source": [
    "### Exporting Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cf9d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7131bb7a",
   "metadata": {},
   "source": [
    "#### Exporting Support Vector Classifier Model & Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac0e99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(svm, open('posneg_lac.pkl', 'wb'))\n",
    "pickle.dump(vec2, open('vec_lac.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9946802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(inc4, open('posneg_full.pkl', 'wb'))\n",
    "pickle.dump(vec, open('vec_full.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101aba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
